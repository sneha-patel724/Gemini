{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# step 1 : install the Google generative AI SDK\n",
        "!pip install -4 google -generative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IHu-gzLexZO",
        "outputId": "76cc0a7a-3945-41af-cdb3-5b33fe86e78f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "no such option: -4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ [\"GOOGLE_API_KEY\"] = \"ENTER API KEY\""
      ],
      "metadata": {
        "id": "Q6_EMReqhXCx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT GENERATION\n"
      ],
      "metadata": {
        "id": "Zx4lUMGgjH0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client() # models\n",
        "\n",
        "#models.generate_content()\n",
        "#model\n",
        "#content-- prompt\n",
        "\n",
        "response = client.models.generate_content(model='gemini-2.5-pro' , contents= \"hey\")\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVwou-pcjKq3",
        "outputId": "bd6008a2-479e-410b-9493-f4d73c0b892a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey there! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJJ8NeFJoHIh",
        "outputId": "0623288f-40a5-4ab4-8af9-af8b7dd98ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GenerateContentResponse(\n",
              "  automatic_function_calling_history=[],\n",
              "  candidates=[\n",
              "    Candidate(\n",
              "      content=Content(\n",
              "        parts=[\n",
              "          Part(\n",
              "            text=\"\"\"Manifestation is the process of turning your thoughts, feelings, and beliefs into your physical reality. It is rooted in the Law of Attraction, the principle that \"like attracts like.\" This suggests that the energy you emit—through your mindset and emotions—attracts experiences of a similar energetic frequency.\n",
              "\n",
              "The process is more than just wishful thinking; it’s a proactive practice involving three key steps:\n",
              "\n",
              "1.  **Intention (Ask):** First, you must have a clear and specific vision of what you want to achieve or attract. Vague desires yield vague results. Clarity is crucial for focusing your energy.\n",
              "\n",
              "2.  **Belief (Align):** You must genuinely believe that your goal is possible and feel the emotions you would have if you already possessed it. This is often practiced through visualization, where you vividly imagine your desired reality. This emotional alignment is considered essential for \"matching the vibration\" of your goal.\n",
              "\n",
              "3.  **Action (Receive):** Manifestation is not passive. It requires taking \"inspired action\"—practical steps that feel aligned with your goal. The universe doesn't just deliver things to your doorstep; it presents opportunities, which you must act upon.\n",
              "\n",
              "Common tools used in manifestation include affirmations (positive statements repeated to reprogram the subconscious mind), vision boards (collages of images representing your goals), and gratitude journaling (focusing on what you already have to cultivate a positive mindset).\n",
              "\n",
              "Ultimately, whether viewed as a spiritual law or a psychological tool, manifestation encourages a positive, goal-oriented mindset. It empowers individuals to overcome limiting beliefs and actively co-create the life they desire through focused intention and deliberate action.\"\"\"\n",
              "          ),\n",
              "        ],\n",
              "        role='model'\n",
              "      ),\n",
              "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
              "      index=0\n",
              "    ),\n",
              "  ],\n",
              "  model_version='gemini-2.5-pro',\n",
              "  response_id='eLfsaLSiGrSgz7IP7ZaM-QI',\n",
              "  sdk_http_response=HttpResponse(\n",
              "    headers=<dict len=10>\n",
              "  ),\n",
              "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
              "    candidates_token_count=338,\n",
              "    prompt_token_count=15,\n",
              "    prompt_tokens_details=[\n",
              "      ModalityTokenCount(\n",
              "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
              "        token_count=15\n",
              "      ),\n",
              "    ],\n",
              "    thoughts_token_count=1353,\n",
              "    total_token_count=1706\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response_2 = client.models.generate_content(model='gemini-2.5-pro' , contents= \"tell about manifestation , explain in 700 words \")\n",
        "print(response_2.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e8bcd9-2f9b-4755-ce75-8edb089dc323",
        "id": "sWJQ1dtbFL26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course. Here is a comprehensive explanation of manifestation.\n",
            "\n",
            "***\n",
            "\n",
            "Manifestation is the practice of turning your thoughts, feelings, and beliefs into your physical reality. At its core, it is a philosophy of co-creation, suggesting that we are active participants in shaping our lives rather than passive observers. It’s not a magical spell or simple wishful thinking; rather, it's an intentional process that combines psychological principles, focused mindset, and proactive effort to bring a desired outcome into existence. Often associated with the Law of Attraction, manifestation is a more holistic practice that involves several key pillars.\n",
            "\n",
            "**1. Clarity and Specific Intention**\n",
            "\n",
            "The first and most crucial step in manifestation is knowing exactly what you want. A vague desire like \"I want to be happy\" or \"I want more money\" is too broad for your mind to focus on. The practice requires specificity. Instead of \"more money,\" a clear intention would be, \"I want to attract an additional $1,000 per month through a creative side project.\" This clarity acts like a destination programmed into a GPS. It gives your thoughts, energy, and actions a precise target to move toward. This step involves deep self-reflection to understand your true desires, not just fleeting wants or goals influenced by others.\n",
            "\n",
            "**2. Belief and Mindset Alignment**\n",
            "\n",
            "Once you have a clear intention, you must genuinely believe it is possible for you to achieve it. This is often the most challenging part, as it requires confronting and overcoming limiting beliefs—the subconscious stories we tell ourselves, such as \"I'm not good enough,\" \"I don't deserve success,\" or \"People like me don't get rich.\" Manifestation posits that your reality is a mirror of your deepest beliefs. To change your reality, you must first change your mind. Techniques like visualization (vividly imagining yourself already having achieved your goal) and affirmations (repeating positive statements that counter your limiting beliefs) are used to reprogram the subconscious mind and align your entire being with the belief that your desire is not just possible, but inevitable.\n",
            "\n",
            "**3. Emotional Alignment and High Vibration**\n",
            "\n",
            "Manifestation is not just about thinking; it's profoundly about *feeling*. The Law of Attraction, a key component, states that \"like attracts like.\" This refers to vibrational energy; every thought and emotion has a frequency. Positive emotions like joy, gratitude, love, and excitement vibrate at a high frequency, while negative emotions like fear, doubt, and jealousy vibrate at a low frequency. To attract your desire, you must match its vibrational frequency. This means cultivating the emotions you *would feel* if you already had what you wanted. The most powerful tool for this is gratitude. By being genuinely grateful for what you already have, you shift your energy from a state of lack to a state of abundance, making you a magnet for more positive experiences.\n",
            "\n",
            "**4. Inspired Action**\n",
            "\n",
            "This pillar debunks the myth that manifestation is a passive process. You cannot simply sit on your couch, visualize a new job, and expect an offer to appear. Manifestation requires you to be an active co-creator. However, the action it calls for is \"inspired action,\" not forced, desperate striving. Inspired action feels intuitive, exciting, and effortless. It’s the sudden urge to call an old friend who ends up having a job lead, the spontaneous decision to sign up for a class where you meet your future business partner, or the creative idea that flows through you. When you are aligned with your intention, you become more attuned to signs, synchronicities, and opportunities that guide you toward your goal. The key is to listen to your intuition and act on these nudges without hesitation.\n",
            "\n",
            "**5. Detachment and Trust (Surrendering the Outcome)**\n",
            "\n",
            "The final, paradoxical step is to let go. After setting your intention, aligning your beliefs and emotions, and taking inspired action, you must release your desperate attachment to the outcome. Obsessing over *when* and *how* your desire will manifest creates resistance, anxiety, and doubt—all low-vibrational emotions that block the process. Trust is essential. It’s like planting a seed: you water it and ensure it gets sunlight, but you don't dig it up every day to see if it’s growing. You trust the process of nature. Similarly, you must trust that the universe (or your subconscious mind) is arranging events in your favor. This surrender allows your manifestation to unfold in its own perfect timing, often in ways more wonderful than you could have planned.\n",
            "\n",
            "In essence, manifestation is a conscious and empowering lifestyle. It's about aligning your internal world—your thoughts, beliefs, and emotions—with your external actions to intentionally craft the life you desire.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response # data+metda_data\n",
        "response_2\n",
        "\n",
        "\"\"\"\n",
        "candiates=[ text]\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Gu4RCBAFrSdt",
        "outputId": "a7f94dd0-6c81-4d24-b6d7-3da0eb7eb9f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncandiates=[ text]\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing all things available in response\n",
        "for i in dir(response_2):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqKptOtfFhg1",
        "outputId": "9273859c-5bba-4901-bfac-100c7bec0aa2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__abstractmethods__\n",
            "__annotations__\n",
            "__class__\n",
            "__class_getitem__\n",
            "__class_vars__\n",
            "__copy__\n",
            "__deepcopy__\n",
            "__delattr__\n",
            "__dict__\n",
            "__dir__\n",
            "__doc__\n",
            "__eq__\n",
            "__fields__\n",
            "__fields_set__\n",
            "__format__\n",
            "__ge__\n",
            "__get_pydantic_core_schema__\n",
            "__get_pydantic_json_schema__\n",
            "__getattr__\n",
            "__getattribute__\n",
            "__getstate__\n",
            "__gt__\n",
            "__hash__\n",
            "__init__\n",
            "__init_subclass__\n",
            "__iter__\n",
            "__le__\n",
            "__lt__\n",
            "__module__\n",
            "__ne__\n",
            "__new__\n",
            "__pretty__\n",
            "__private_attributes__\n",
            "__pydantic_complete__\n",
            "__pydantic_computed_fields__\n",
            "__pydantic_core_schema__\n",
            "__pydantic_custom_init__\n",
            "__pydantic_decorators__\n",
            "__pydantic_extra__\n",
            "__pydantic_fields__\n",
            "__pydantic_fields_set__\n",
            "__pydantic_generic_metadata__\n",
            "__pydantic_init_subclass__\n",
            "__pydantic_parent_namespace__\n",
            "__pydantic_post_init__\n",
            "__pydantic_private__\n",
            "__pydantic_root_model__\n",
            "__pydantic_serializer__\n",
            "__pydantic_setattr_handlers__\n",
            "__pydantic_validator__\n",
            "__reduce__\n",
            "__reduce_ex__\n",
            "__replace__\n",
            "__repr__\n",
            "__repr_args__\n",
            "__repr_name__\n",
            "__repr_recursion__\n",
            "__repr_str__\n",
            "__rich_repr__\n",
            "__setattr__\n",
            "__setstate__\n",
            "__signature__\n",
            "__sizeof__\n",
            "__slots__\n",
            "__str__\n",
            "__subclasshook__\n",
            "__weakref__\n",
            "_abc_impl\n",
            "_calculate_keys\n",
            "_copy_and_set_values\n",
            "_from_response\n",
            "_get_text\n",
            "_get_value\n",
            "_iter\n",
            "_setattr_handler\n",
            "automatic_function_calling_history\n",
            "candidates\n",
            "code_execution_result\n",
            "construct\n",
            "copy\n",
            "create_time\n",
            "dict\n",
            "executable_code\n",
            "from_orm\n",
            "function_calls\n",
            "json\n",
            "model_computed_fields\n",
            "model_config\n",
            "model_construct\n",
            "model_copy\n",
            "model_dump\n",
            "model_dump_json\n",
            "model_extra\n",
            "model_fields\n",
            "model_fields_set\n",
            "model_json_schema\n",
            "model_parametrized_name\n",
            "model_post_init\n",
            "model_rebuild\n",
            "model_validate\n",
            "model_validate_json\n",
            "model_validate_strings\n",
            "model_version\n",
            "parse_file\n",
            "parse_obj\n",
            "parse_raw\n",
            "parsed\n",
            "parts\n",
            "prompt_feedback\n",
            "response_id\n",
            "schema\n",
            "schema_json\n",
            "sdk_http_response\n",
            "text\n",
            "to_json_dict\n",
            "update_forward_refs\n",
            "usage_metadata\n",
            "validate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# type\n",
        "print(type(response_2))"
      ],
      "metadata": {
        "id": "4x8I-Osuwmm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e0e8d4-3be4-4e40-a968-d8b883ab762c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'google.genai.types.GenerateContentResponse'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENS"
      ],
      "metadata": {
        "id": "0ZfA8gt9IGcT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Prompt_Token_Count\n",
        "\n",
        "This tells us how many tokens were in your prompt, i.e, the input you sent\n",
        "\n",
        "[ tell about manifestation , explain in 700 words ]"
      ],
      "metadata": {
        "id": "Dna_zi_4Io7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Candidate Token Count\n",
        "\n",
        "It refers to the number of tokens in the final output. The actual answer the model generated for your input. These do not include your input or internal reasoning. Just the actual answer.\n",
        "\n",
        "NOTE: no thiniking capabilities"
      ],
      "metadata": {
        "id": "KcbT8B-qKILR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Thoughts Token Count\n",
        "\n",
        "This is Gemini-specific and unique to models that support \"thinking\" (chain-of-thought, tool use, intermediate reasoning).\n",
        "\n",
        "It tells how many tokens were used by the model in its internal reasoning steps.\n",
        "\n",
        "for example:\n",
        "\n",
        "a) Thinking out the answer\n",
        "\n",
        "b) Using intermediate reasoning (like step by step breakdown)"
      ],
      "metadata": {
        "id": "6FsklD_rMZTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Total Token Count\n",
        "\n",
        "This is simply the sum of everything\n",
        "\n",
        "prompt_token_count + candidate_token_count + thoughts_token_count = total_token_Count"
      ],
      "metadata": {
        "id": "TSp-X1blNQbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response_3 = client.models.generate_content(model='gemini-2.0-flash' , contents= \"tell about manifestation , explain in 700 words \")\n",
        "response_3\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Now we will use Gemini 2.0 Flash. In this model, there is no thoughts token count, meaning the model won’t “think”; it will directly give the output. It will only have candidate, total, and prompt token counts.\n",
        "\n",
        "If we want to do lightweight tasks quickly, we can use such models where we need the output immediately. For example, if I want to do a simple math operation like 7 + 7, the output will directly be 14.\n",
        "\n",
        "So, for simple tasks, we can use these models to get fast results.\n",
        "\n",
        "NOTE: Gemini old model's doesn't have thinking capabilities\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f2de3612-840a-4cc7-b946-3df26e83e76f",
        "id": "RpdPrPPxOK4R"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nNow we will use Gemini 2.0 Flash. In this model, there is no thoughts token count, meaning the model won’t “think”; it will directly give the output. It will only have candidate, total, and prompt token counts.\\n\\nIf we want to do lightweight tasks quickly, we can use such models where we need the output immediately. For example, if I want to do a simple math operation like 7 + 7, the output will directly be 14.\\n\\nSo, for simple tasks, we can use these models to get fast results.\\n\\nNOTE: Gemini old model's doesn't have thinking capabilities\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the response doesn’t have thought tokens, which means the model didn’t think, it gave the answer directly."
      ],
      "metadata": {
        "id": "Iq2wWRB1Rptw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional Configuration\n",
        "It is nothing but a rule book to customize our model.\n",
        "\n",
        "for example:\n",
        "\n",
        "i want my model to act as a - rude, polite, researcher, or\n",
        "\n",
        "i want my model to give output in image, audio, text etc."
      ],
      "metadata": {
        "id": "cis-hBSGUA_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Instructions\n",
        "model - persona...\n",
        "\n",
        "System instructions are special directives provided to AI models (like Gemini) to guide how they should behave during a conversation.\n",
        "These instructions are not visible to users in the typical interface but are set in the background by developers or platforms.\n",
        "\n",
        "They define the model's: tone, personality, level of detail, preferred style of responses, and even what it should or shouldn't talk about.\n",
        "\n",
        "They allow developers to tailor the AI's behaviour to specific use case-like customer support, education, or content generation-without needing to repeat instructions in every prompt.\n",
        "\n",
        "In essence, system instructions are like settings the \"personality and boundaries\" of an AI before it starts any conversation."
      ],
      "metadata": {
        "id": "CX9dgoaZVqNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "1. generate_content()\n",
        "2. models - customize -- rude, polite, researcher, image, audio, text\n",
        "3. parameter config\n",
        "4. generatecontentconfig class object -- rule\n",
        "5. system instructions\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HxYM9zPDtGQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai import types\n",
        "# now see what happens when i give system instruction to my gemini model to behave like a rude people. See how my model replies when i'm asking (\"hello boy friend,why you not talking to me\" ?)\n",
        "response_4 = client.models.generate_content(\n",
        "     model = \"gemini-2.5-flash-lite\",\n",
        "    contents = \" hello boy friend , why you not talking to me \",\n",
        "    config = types.GenerateContentConfig(system_instruction =\"Behave like a very rude person,who speaks very rudely to the people,give reply in 2 sentences\"))\n",
        "print(response_4.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KEvGupbtQIz",
        "outputId": "50d16529-948c-45e8-f85a-4087473b215c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What the hell are you yammering about? I'm not your boyfriend, so quit your whining and leave me the hell alone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now see what happens when i give system instruction to my gemini model to behave like a rude people. See how my model give me answer when i'm asking (hello boyfriend,when will we meet)\n",
        "response_5 = client.models.generate_content(model='gemini-2.5-flash-lite',\n",
        "                                            contents=\"hello boy friend, when will we meet\",\n",
        "                                            config=types.GenerateContentConfig(system_instruction=\"Behave like a very rude perosn, who speaks very rudely to the people,but you never abuse, give reply in 2 sentences\"))\n",
        "print(response_5.text)"
      ],
      "metadata": {
        "id": "pkxMIWmZvZ8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c651c3-c90a-4d87-a964-ffac63758834"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can't you see I'm busy? Stop bothering me with your pathetic questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now see what happens when i give system instruction to my gemini model to behave like a polite people. See how my model give me answer when i'm asking (hello husband, do you even love me)\n",
        "response_7 = client.models.generate_content(model='gemini-2.5-flash-lite',\n",
        "                                            contents=\"hello husband, do you even love me \",\n",
        "                                            config=types.GenerateContentConfig(system_instruction=\"Behave like a very polite perosn, who speaks very politely to the people, give reply in 2 sentences\"))\n",
        "print(response_7.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsC1WMVTyk1A",
        "outputId": "ada6b8dc-5a8f-4395-aa82-0f88b52aa777"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My dearest wife, of course I love you with all my heart, your presence in my life brings me immeasurable joy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now see what happens when i give system instruction to my gemini model to behave like a polite people. See how my model replies when i'm asking (how're you ?)\n",
        "response_6 = client.models.generate_content(model='gemini-2.5-flash-lite',\n",
        "                                            contents=\"hey baby ,stop fighting with me\",\n",
        "                                            config=types.GenerateContentConfig(system_instruction=\"Behave like a very polite perosn, who speaks very politely to the people, give reply in 2 sentences\"))\n",
        "print(response_6.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6MyyBNr2TYa",
        "outputId": "1ed4f2d9-7801-4bf4-c6b0-1c684981d5ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I understand you're feeling upset, and I apologize if my actions have caused any distress. Please know that my intention is never to fight, and I'd like to resolve this peacefully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# real world example of system instructions\n",
        "client = genai.Client()\n",
        "\n",
        "# detailed system instructions\n",
        "system_instructions = \"\"\"\n",
        "\"You are a corporate legal assistant.\"\n",
        "            \"Your job is to extract the following from any B2B contract text:\"\n",
        "            \"1. Contract start and end dates.\"\n",
        "            \"2. Payment terms,\"\n",
        "            \"3. Termination conditions,\"\n",
        "            \"4. Any penalty or liability clauses.\"\n",
        "            \"Output only what you find.\"\n",
        "            \"I need the output in tabular form\"\n",
        "\"\"\"\n",
        "\n",
        "#content\n",
        "contents=\"\"\"\n",
        "        This agreement is entered into on May 1st, 2024 and shall remain in effect until April 30, 2025.\n",
        "        Payment is due within 45 days of invoice date. Late payments may incur a penalty of 3% monthly.\n",
        "        Either party may terminate this agreement with 60 days' notice.\n",
        "\"\"\"\n",
        "\n",
        "#model\n",
        "response_8 = client.models.generate_content(model='gemini-2.5-flash',\n",
        "                                            contents=contents,\n",
        "                                            config=types.GenerateContentConfig(system_instruction=system_instructions))\n",
        "print(response_8.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMwEJulB60q_",
        "outputId": "1345a3d6-a914-4c87-ec7f-d0104ae77bc9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Category                     | Details                                       |\n",
            "| :--------------------------- | :-------------------------------------------- |\n",
            "| **Contract Start Date**      | May 1st, 2024                                 |\n",
            "| **Contract End Date**        | April 30, 2025                                |\n",
            "| **Payment Terms**            | Due within 45 days of invoice date            |\n",
            "| **Termination Conditions**   | Either party may terminate with 60 days' notice |\n",
            "| **Penalty/Liability Clauses** | Late payments may incur a penalty of 3% monthly |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. max output tokens\n",
        "2. sets a hard cap on how long the model's response ca be (1 token = % words)\n",
        "\"\"\"\n",
        "response_9 = client.models.generate_content(model='gemini-2.5-flash-lite',\n",
        "                                            contents=\"What is deep learning ?\",\n",
        "                                            config=types.GenerateContentConfig(max_output_tokens=100))\n",
        "print(response_9.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD_MhF9c8OgL",
        "outputId": "e64297bf-e5aa-4ede-af43-8fb5b30c7fc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep learning is a **subset of machine learning** that uses **artificial neural networks with multiple layers** to learn complex patterns from data. The \"deep\" in deep learning refers to the **depth of these neural networks**, meaning they have many layers between the input and output layers.\n",
            "\n",
            "Think of it like this:\n",
            "\n",
            "*   **Traditional Machine Learning:** You might manually tell the computer what features to look for (e.g., \"if the image has roundness and a stem, it might\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "CandidateCount optional: Number of generated responses to return.\n",
        "If unset, this will default to 1. Please note this doesn't work for\n",
        "previous generation models (Gemini 1.0 family)\n",
        "\"\"\"\n",
        "from google.genai import types\n",
        "response_10 = client.models.generate_content(model='gemini-2.5-flash-lite',\n",
        "                                            contents=\"What is deep learning ? in 100 words\",\n",
        "                                            config=types.GenerateContentConfig(candidateCount=2))\n",
        "print(response_10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mozwj_CGHAmL",
        "outputId": "ce535d2c-440a-49c2-e08a-6e70fb498a83"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sdk_http_response=HttpResponse(\n",
            "  headers=<dict len=10>\n",
            ") candidates=[Candidate(\n",
            "  content=Content(\n",
            "    parts=[\n",
            "      Part(\n",
            "        text='Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers (deep architectures). These layers learn hierarchical representations of data, starting from simple features and progressing to more complex ones. This allows deep learning models to automatically discover intricate patterns in vast amounts of data, such as images, text, and audio. Unlike traditional machine learning, deep learning often requires less manual feature engineering, enabling powerful applications in areas like image recognition, natural language processing, and speech synthesis.'\n",
            "      ),\n",
            "      Part(\n",
            "        text='Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers to learn complex patterns from data. These \"deep\" networks, inspired by the human brain, process information through successive layers, with each layer extracting progressively more abstract features. This hierarchical learning allows deep learning models to excel at tasks like image recognition, natural language processing, and speech synthesis, often achieving state-of-the-art results without explicit human feature engineering. It requires vast amounts of data and significant computational power to train effectively.'\n",
            "      ),\n",
            "    ],\n",
            "    role='model'\n",
            "  ),\n",
            "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
            "  index=0\n",
            "), Candidate(\n",
            "  content=Content(\n",
            "    parts=[\n",
            "      Part(\n",
            "        text='Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers to learn complex patterns from data. These \"deep\" networks, inspired by the human brain, process information through successive layers, with each layer extracting progressively more abstract features. This hierarchical learning allows deep learning models to excel at tasks like image recognition, natural language processing, and speech synthesis, often achieving state-of-the-art results without explicit human feature engineering. It requires vast amounts of data and significant computational power to train effectively.'\n",
            "      ),\n",
            "    ],\n",
            "    role='model'\n",
            "  ),\n",
            "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
            "  index=1\n",
            ")] create_time=None model_version='gemini-2.5-flash-lite' prompt_feedback=None response_id='UrL7aOy6MJugjrEPp4_t0AU' usage_metadata=GenerateContentResponseUsageMetadata(\n",
            "  candidates_token_count=96,\n",
            "  prompt_token_count=12,\n",
            "  prompt_tokens_details=[\n",
            "    ModalityTokenCount(\n",
            "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
            "      token_count=12\n",
            "    ),\n",
            "  ],\n",
            "  total_token_count=108\n",
            ") automatic_function_calling_history=[] parsed=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, candidate in enumerate(response_10.candidates):\n",
        "  print(f\"Candidate{i+1}:\\n{candidate.content.parts[0].text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcpK2ug2JMc9",
        "outputId": "961505c0-8080-41af-a33c-0bea93a8fdee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate1:\n",
            "Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers (deep architectures). These layers learn hierarchical representations of data, starting from simple features and progressing to more complex ones. This allows deep learning models to automatically discover intricate patterns in vast amounts of data, such as images, text, and audio. Unlike traditional machine learning, deep learning often requires less manual feature engineering, enabling powerful applications in areas like image recognition, natural language processing, and speech synthesis.\n",
            "Candidate2:\n",
            "Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers to learn complex patterns from data. These \"deep\" networks, inspired by the human brain, process information through successive layers, with each layer extracting progressively more abstract features. This hierarchical learning allows deep learning models to excel at tasks like image recognition, natural language processing, and speech synthesis, often achieving state-of-the-art results without explicit human feature engineering. It requires vast amounts of data and significant computational power to train effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNE9_kLtJofm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}